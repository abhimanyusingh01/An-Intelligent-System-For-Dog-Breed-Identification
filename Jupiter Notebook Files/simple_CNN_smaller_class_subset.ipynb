{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "seed = 16\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to build/test working model using a smaller subset of classes and data to minimize iteration time and to test CovNets of varying size before running on broader dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10183346064960334723\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1493781708\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 45552984422354421\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#check using system GPU for processing\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied over the train, validate and test sets for 5 randomly selected breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the subset, I copied over their respesctive train/validate/test image folders from the broader image data set.  I maintained the full size of each train, val and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Garrick\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets_subset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 5 classes.\n",
      "Found 100 images belonging to 5 classes.\n",
      "Found 389 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15, shear_range=0.1, channel_shift_range=20,\n",
    "                                    width_shift_range=0.1,  height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True,\n",
    "                                    fill_mode='nearest', rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('subset_train', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('subset_val', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('subset_test', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# reminder to self... flow_from_directory infers the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing keras modules and setting up a few parameters, instantiating early stopping\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import keras.utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "# tf_config.gpu_options.allow_growth = True **this causes python to crash, error: las.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\n",
    "sess = tf.Session(config=tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          65600     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 221,573\n",
      "Trainable params: 221,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224, 3)\n",
    "num_classes = 5\n",
    "\n",
    "# will create a few different models.... initial base model \n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(Flatten())\n",
    "\n",
    "base_model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(Dropout(0.2))\n",
    "base_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "epochs = 10\n",
    "lrate = 0.003\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 39s 387ms/step - loss: 1.6262 - acc: 0.1252 - val_loss: 1.6064 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 47s 475ms/step - loss: 1.6141 - acc: 0.1580 - val_loss: 1.5952 - val_acc: 0.2600\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 1.6025 - acc: 0.2452 - val_loss: 1.5641 - val_acc: 0.2800\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 1.5770 - acc: 0.2528 - val_loss: 1.5359 - val_acc: 0.2600\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 49s 491ms/step - loss: 1.5524 - acc: 0.2804 - val_loss: 1.5027 - val_acc: 0.2900\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 49s 489ms/step - loss: 1.5197 - acc: 0.3080 - val_loss: 1.5119 - val_acc: 0.3200\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 49s 489ms/step - loss: 1.5007 - acc: 0.3052 - val_loss: 1.4867 - val_acc: 0.3000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 49s 489ms/step - loss: 1.4851 - acc: 0.3252 - val_loss: 1.4460 - val_acc: 0.3900\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 48s 483ms/step - loss: 1.4691 - acc: 0.3484 - val_loss: 1.4391 - val_acc: 0.4000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 1.4357 - acc: 0.3784 - val_loss: 1.4155 - val_acc: 0.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2261368c7f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train base_model\n",
    "\n",
    "base_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=100, epochs=epochs, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-608e06a428d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# same model, more epochs (10 -> 50) and fewere steps per epoch, prior model params saw train and validate accuracies double, expecting the model to be within 80% acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m base_model.fit_generator(train_generator, validation_data=validation_generator,\n\u001b[0m\u001b[0;32m      4\u001b[0m                     steps_per_epoch=50, epochs=25, callbacks=[early_stopping])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "# same model, more epochs (10 -> 50) and fewere steps per epoch, prior model params saw train and validate accuracies double, expecting the model to be within 80% acc\n",
    "\n",
    "base_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=50, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are increasing in accuracy with each successive epoch, perhaps need to train for more epochs. Let's test a deeper network with the same amount of epochs and see if we can begin with a better first epoch accuracy of 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 25, 25, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 288)               83232     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1445      \n",
      "=================================================================\n",
      "Total params: 144,933\n",
      "Trainable params: 144,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# taking the base model and adding more hidden layers\n",
    "\n",
    "deep_model = Sequential()\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Flatten())\n",
    "\n",
    "deep_model.add(Dense(288, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Dropout(0.2))\n",
    "deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "epochs = 10\n",
    "lrate = 0.003\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "deep_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 50s 496ms/step - loss: 1.6209 - acc: 0.1364 - val_loss: 1.6092 - val_acc: 0.1800\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 1.6205 - acc: 0.1112 - val_loss: 1.6094 - val_acc: 0.2000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 50s 497ms/step - loss: 1.6122 - acc: 0.1644 - val_loss: 1.6038 - val_acc: 0.2700\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 50s 497ms/step - loss: 1.6074 - acc: 0.2400 - val_loss: 1.5855 - val_acc: 0.3000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 50s 495ms/step - loss: 1.5968 - acc: 0.2500 - val_loss: 1.5488 - val_acc: 0.3400\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 1.5761 - acc: 0.2812 - val_loss: 1.5453 - val_acc: 0.3100\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 1.5551 - acc: 0.3064 - val_loss: 1.4878 - val_acc: 0.3700\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 50s 496ms/step - loss: 1.5262 - acc: 0.3116 - val_loss: 1.4948 - val_acc: 0.3800\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 1.5142 - acc: 0.3272 - val_loss: 1.4632 - val_acc: 0.3700\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 51s 511ms/step - loss: 1.4806 - acc: 0.3444 - val_loss: 1.3815 - val_acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2047dd37eb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train deeper model\n",
    "\n",
    "deep_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=100, epochs=epochs, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 1.4756 - acc: 0.3436 - val_loss: 1.3821 - val_acc: 0.4700\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 1.4540 - acc: 0.3536 - val_loss: 1.3937 - val_acc: 0.4300\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 49s 488ms/step - loss: 1.4160 - acc: 0.3924 - val_loss: 1.3869 - val_acc: 0.4100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2048c3c54e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like the deeper model overfits the training data, but performs better on the validation data... let's train for more epochs\n",
    "\n",
    "deep_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=100, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 43s 431ms/step - loss: 1.1137 - acc: 0.5544 - val_loss: 1.4292 - val_acc: 0.4400\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 48s 480ms/step - loss: 1.0815 - acc: 0.5672 - val_loss: 1.4291 - val_acc: 0.4500\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 49s 488ms/step - loss: 1.0484 - acc: 0.5800 - val_loss: 1.3839 - val_acc: 0.4900\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 1.0520 - acc: 0.5760 - val_loss: 1.3593 - val_acc: 0.4600\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 48s 483ms/step - loss: 1.0108 - acc: 0.5976 - val_loss: 1.5123 - val_acc: 0.4800\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 51s 511ms/step - loss: 0.9848 - acc: 0.6028 - val_loss: 1.4050 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2047dd37f98>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deeper model ran into early stopping on the validation set\n",
    "\n",
    "# lets try base model with more epochs\n",
    "\n",
    "base_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=100, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 25, 25, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 288)               83232     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 1445      \n",
      "=================================================================\n",
      "Total params: 144,933\n",
      "Trainable params: 144,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# deep model with Adam optimizer\n",
    "\n",
    "# taking the base model and adding more hidden layers\n",
    "\n",
    "\n",
    "\n",
    "deep_model_Adam = Sequential()\n",
    "\n",
    "deep_model_Adam = Sequential()\n",
    "deep_model_Adam.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_Adam.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_Adam.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_Adam.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam.add(Flatten())\n",
    "\n",
    "deep_model_Adam.add(Dense(288, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam.add(Dropout(0.2))\n",
    "deep_model_Adam.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "deep_model_Adam.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(deep_model_Adam.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 52s 519ms/step - loss: 1.6144 - acc: 0.1948 - val_loss: 1.6012 - val_acc: 0.2600\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 53s 533ms/step - loss: 1.5928 - acc: 0.2372 - val_loss: 1.5298 - val_acc: 0.3700\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 1.5182 - acc: 0.3160 - val_loss: 1.4673 - val_acc: 0.3400\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 53s 534ms/step - loss: 1.4677 - acc: 0.3624 - val_loss: 1.3619 - val_acc: 0.4200\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 1.4201 - acc: 0.3836 - val_loss: 1.3594 - val_acc: 0.3600\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 52s 519ms/step - loss: 1.3792 - acc: 0.3968 - val_loss: 1.3576 - val_acc: 0.4000\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 1.3895 - acc: 0.3828 - val_loss: 1.3431 - val_acc: 0.4600\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 57s 570ms/step - loss: 1.3295 - acc: 0.4356 - val_loss: 1.3494 - val_acc: 0.4300\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 52s 518ms/step - loss: 1.3122 - acc: 0.4400 - val_loss: 1.3269 - val_acc: 0.4700\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 50s 500ms/step - loss: 1.3254 - acc: 0.4276 - val_loss: 1.3145 - val_acc: 0.4900\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 50s 495ms/step - loss: 1.2971 - acc: 0.4472 - val_loss: 1.3218 - val_acc: 0.4500\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 51s 514ms/step - loss: 1.2844 - acc: 0.4608 - val_loss: 1.2981 - val_acc: 0.4900\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 1.2628 - acc: 0.4672 - val_loss: 1.2958 - val_acc: 0.4900\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 53s 533ms/step - loss: 1.2262 - acc: 0.4824 - val_loss: 1.2877 - val_acc: 0.5100\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 51s 505ms/step - loss: 1.2562 - acc: 0.4684 - val_loss: 1.3059 - val_acc: 0.4700\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 50s 498ms/step - loss: 1.2159 - acc: 0.5080 - val_loss: 1.3386 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e0ce440b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_Adam.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=100, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 109, 109, 64)      12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 52, 52, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 870,053\n",
      "Trainable params: 870,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# tweaked deep model w/ Adam optimizer.  Deeper network topology near the input (less convolution than prior models), more FC nodes\n",
    "\n",
    "deep_model_Adam_2 = Sequential()\n",
    "\n",
    "deep_model_Adam_2 = Sequential()\n",
    "deep_model_Adam_2.add(Conv2D(64, (8, 8), strides=2, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_Adam_2.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_Adam_2.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_Adam_2.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam_2.add(Flatten())\n",
    "\n",
    "deep_model_Adam_2.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_Adam_2.add(Dropout(0.2))\n",
    "deep_model_Adam_2.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "deep_model_Adam_2.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(deep_model_Adam_2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 1.6373 - acc: 0.1040 - val_loss: 1.6094 - val_acc: 0.2100\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 27s 543ms/step - loss: 1.6099 - acc: 0.1312 - val_loss: 1.6093 - val_acc: 0.2700\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 1.6101 - acc: 0.1248 - val_loss: 1.6093 - val_acc: 0.1800\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.6100 - acc: 0.1440 - val_loss: 1.6087 - val_acc: 0.2100\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 25s 504ms/step - loss: 1.6100 - acc: 0.1712 - val_loss: 1.6093 - val_acc: 0.2100\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 1.6124 - acc: 0.1560 - val_loss: 1.6094 - val_acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e0c77d710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_Adam_2.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=50, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deeper topology not necessarily better and is over-fitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 109, 109, 64)      12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 52, 52, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 870,053\n",
      "Trainable params: 870,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# tweaked deep model w/ RMSProp optimizer again with Deeper network topology near the input (less convolution than prior models), more FC nodes\n",
    "\n",
    "deep_model_RMS = Sequential()\n",
    "\n",
    "deep_model_RMS = Sequential()\n",
    "deep_model_RMS.add(Conv2D(64, (8, 8), strides=2, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_RMS.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_RMS.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_RMS.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_RMS.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_RMS.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model_RMS.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_RMS.add(Flatten())\n",
    "\n",
    "deep_model_RMS.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_RMS.add(Dropout(0.2))\n",
    "deep_model_RMS.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "deep_model_RMS.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(deep_model_RMS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 50s 502ms/step - loss: 1.8105 - acc: 0.0744 - val_loss: 1.6091 - val_acc: 0.2300\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 50s 498ms/step - loss: 1.6849 - acc: 0.1940 - val_loss: 1.5901 - val_acc: 0.2900\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 51s 514ms/step - loss: 1.7109 - acc: 0.2660 - val_loss: 1.5100 - val_acc: 0.3800\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 1.6232 - acc: 0.3440 - val_loss: 1.5153 - val_acc: 0.3700\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 49s 495ms/step - loss: 1.4819 - acc: 0.3592 - val_loss: 1.4684 - val_acc: 0.3900\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 1.4970 - acc: 0.3952 - val_loss: 1.4337 - val_acc: 0.4300\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 1.3743 - acc: 0.4148 - val_loss: 1.4509 - val_acc: 0.3700\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 49s 489ms/step - loss: 1.3472 - acc: 0.4396 - val_loss: 1.4362 - val_acc: 0.4100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e110a0860>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_RMS.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=100, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               1384704   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,405,381\n",
      "Trainable params: 1,405,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# so more layers doesn't work.... let us keep the standard 3 CONV layers and widen the toplogy\n",
    "\n",
    "wide_model = Sequential()\n",
    "wide_model.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model.add(Conv2D(32, (3, 3), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model.add(Flatten())\n",
    "\n",
    "wide_model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model.add(Dropout(0.2))\n",
    "wide_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "epochs = 10\n",
    "wide_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 1.6786 - acc: 0.1352 - val_loss: 1.5989 - val_acc: 0.2400\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 23s 467ms/step - loss: 1.6084 - acc: 0.2248 - val_loss: 1.5867 - val_acc: 0.3300\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 1.6061 - acc: 0.2192 - val_loss: 1.5725 - val_acc: 0.2800\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 1.6008 - acc: 0.2120 - val_loss: 1.5623 - val_acc: 0.2800\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 1.5650 - acc: 0.3064 - val_loss: 1.5225 - val_acc: 0.3300\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 1.5702 - acc: 0.2808 - val_loss: 1.4849 - val_acc: 0.3800\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 1.5391 - acc: 0.3504 - val_loss: 1.4880 - val_acc: 0.3700\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 1.5081 - acc: 0.3280 - val_loss: 1.4409 - val_acc: 0.4300\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 1.4535 - acc: 0.3872 - val_loss: 1.3872 - val_acc: 0.4500\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 1.4138 - acc: 0.4064 - val_loss: 1.3917 - val_acc: 0.4600\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 1.3901 - acc: 0.4360 - val_loss: 1.3567 - val_acc: 0.4200\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 1.3658 - acc: 0.4464 - val_loss: 1.3562 - val_acc: 0.4300\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 1.3460 - acc: 0.4432 - val_loss: 1.4031 - val_acc: 0.4200\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 1.3438 - acc: 0.4480 - val_loss: 1.4012 - val_acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12df0df25f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=50, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-528c70b253cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# wider doesn't necessarily work... however, slowing the learning rate seems to having a positive impact. same model as above, decrease LR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwide_model_slow_learn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mwide_model_slow_learn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwide_model_slow_learn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# wider doesn't necessarily work... however, slowing the learning rate seems to having a positive impact. same model as above, decrease LR\n",
    "\n",
    "wide_model_slow_learn = Sequential()\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model_slow_learn.add(Flatten())\n",
    "\n",
    "wide_model_slow_learn.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(Dropout(0.2))\n",
    "wide_model_slow_learn.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "wide_model_slow_learn.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(wide_model_slow_learn.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 1.6161 - acc: 0.1824 - val_loss: 1.6017 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 1.6093 - acc: 0.2168 - val_loss: 1.5971 - val_acc: 0.2300\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.6005 - acc: 0.2424 - val_loss: 1.5925 - val_acc: 0.2400\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 1.5992 - acc: 0.2416 - val_loss: 1.5873 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 1.5852 - acc: 0.2912 - val_loss: 1.5849 - val_acc: 0.2500\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.5902 - acc: 0.2728 - val_loss: 1.5799 - val_acc: 0.2800\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 1.5895 - acc: 0.2640 - val_loss: 1.5757 - val_acc: 0.2800\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5795 - acc: 0.3040 - val_loss: 1.5712 - val_acc: 0.3300\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.5745 - acc: 0.3008 - val_loss: 1.5665 - val_acc: 0.2900\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.5724 - acc: 0.2984 - val_loss: 1.5615 - val_acc: 0.3100\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.5681 - acc: 0.3232 - val_loss: 1.5565 - val_acc: 0.3100\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 25s 490ms/step - loss: 1.5649 - acc: 0.3368 - val_loss: 1.5512 - val_acc: 0.3300\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 1.5577 - acc: 0.3128 - val_loss: 1.5476 - val_acc: 0.3300\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5471 - acc: 0.3544 - val_loss: 1.5426 - val_acc: 0.3300\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 1.5523 - acc: 0.3048 - val_loss: 1.5362 - val_acc: 0.3300\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5507 - acc: 0.3152 - val_loss: 1.5308 - val_acc: 0.3600\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 1.5384 - acc: 0.3504 - val_loss: 1.5242 - val_acc: 0.3600\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 1.5231 - acc: 0.3672 - val_loss: 1.5195 - val_acc: 0.3300\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5261 - acc: 0.3224 - val_loss: 1.5139 - val_acc: 0.3600\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.5115 - acc: 0.3824 - val_loss: 1.5105 - val_acc: 0.3800\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.5173 - acc: 0.3720 - val_loss: 1.5025 - val_acc: 0.3700\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 1.5127 - acc: 0.3584 - val_loss: 1.4958 - val_acc: 0.3400\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 1.5039 - acc: 0.3600 - val_loss: 1.4912 - val_acc: 0.3800\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 1.5025 - acc: 0.3728 - val_loss: 1.4871 - val_acc: 0.4300\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 1.4911 - acc: 0.3712 - val_loss: 1.4816 - val_acc: 0.4100\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 25s 501ms/step - loss: 1.4990 - acc: 0.3472 - val_loss: 1.4752 - val_acc: 0.3700\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 1.4839 - acc: 0.3840 - val_loss: 1.4707 - val_acc: 0.4000\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 1.4786 - acc: 0.3776 - val_loss: 1.4653 - val_acc: 0.3900\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 1.4721 - acc: 0.3976 - val_loss: 1.4640 - val_acc: 0.3500\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 1.4756 - acc: 0.4048 - val_loss: 1.4622 - val_acc: 0.4300\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.4647 - acc: 0.3848 - val_loss: 1.4617 - val_acc: 0.4200\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 1.4651 - acc: 0.3920 - val_loss: 1.4502 - val_acc: 0.4400\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.4579 - acc: 0.4040 - val_loss: 1.4495 - val_acc: 0.4400\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.4593 - acc: 0.3816 - val_loss: 1.4448 - val_acc: 0.4000\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 1.4666 - acc: 0.3688 - val_loss: 1.4429 - val_acc: 0.4000\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.4547 - acc: 0.3920 - val_loss: 1.4359 - val_acc: 0.3900\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 32s 636ms/step - loss: 1.4349 - acc: 0.4112 - val_loss: 1.4398 - val_acc: 0.4000\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 1.4350 - acc: 0.3960 - val_loss: 1.4370 - val_acc: 0.4700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e9d96c278>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_model_slow_learn.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=50, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it appears a slower learning rate might be key in allowing prior models to train for more epochs... \n",
    "# let's try a few earlier models with a decreased learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 25, 25, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 288)               83232     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 1445      \n",
      "=================================================================\n",
      "Total params: 144,933\n",
      "Trainable params: 144,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "deep_model_Adam.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(deep_model_Adam.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 1.6217 - acc: 0.1968 - val_loss: 1.6168 - val_acc: 0.1800\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 1.6266 - acc: 0.1760 - val_loss: 1.6126 - val_acc: 0.1900\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 1.6167 - acc: 0.1840 - val_loss: 1.6093 - val_acc: 0.2100\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 1.6085 - acc: 0.2272 - val_loss: 1.6074 - val_acc: 0.2300\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 1.6126 - acc: 0.2000 - val_loss: 1.6057 - val_acc: 0.2300\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 1.6127 - acc: 0.2008 - val_loss: 1.6047 - val_acc: 0.2400\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 25s 490ms/step - loss: 1.5997 - acc: 0.2576 - val_loss: 1.6034 - val_acc: 0.2300\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 1.6084 - acc: 0.2352 - val_loss: 1.6024 - val_acc: 0.2200\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.6039 - acc: 0.2144 - val_loss: 1.6010 - val_acc: 0.2000\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 27s 548ms/step - loss: 1.6065 - acc: 0.2192 - val_loss: 1.6002 - val_acc: 0.2400\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 1.5996 - acc: 0.2328 - val_loss: 1.5988 - val_acc: 0.2400\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.6031 - acc: 0.2200 - val_loss: 1.5978 - val_acc: 0.2600\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 1.5976 - acc: 0.2592 - val_loss: 1.5961 - val_acc: 0.2600\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5962 - acc: 0.2616 - val_loss: 1.5942 - val_acc: 0.3000\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5957 - acc: 0.2720 - val_loss: 1.5929 - val_acc: 0.2900\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 1.5944 - acc: 0.2392 - val_loss: 1.5906 - val_acc: 0.3400\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 1.5869 - acc: 0.2808 - val_loss: 1.5875 - val_acc: 0.3300\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 1.5932 - acc: 0.2528 - val_loss: 1.5851 - val_acc: 0.3700\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5814 - acc: 0.3104 - val_loss: 1.5820 - val_acc: 0.3300\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5824 - acc: 0.2904 - val_loss: 1.5792 - val_acc: 0.3500\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 1.5786 - acc: 0.2808 - val_loss: 1.5749 - val_acc: 0.3400\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 1.5767 - acc: 0.2904 - val_loss: 1.5704 - val_acc: 0.3600\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5769 - acc: 0.2760 - val_loss: 1.5658 - val_acc: 0.3900\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 1.5699 - acc: 0.3080 - val_loss: 1.5609 - val_acc: 0.3900\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 1.5642 - acc: 0.3016 - val_loss: 1.5561 - val_acc: 0.3700\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 1.5559 - acc: 0.3272 - val_loss: 1.5499 - val_acc: 0.3800\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5589 - acc: 0.2984 - val_loss: 1.5437 - val_acc: 0.3500\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5496 - acc: 0.3056 - val_loss: 1.5376 - val_acc: 0.3500\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 1.5529 - acc: 0.3008 - val_loss: 1.5337 - val_acc: 0.3600\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 1.5579 - acc: 0.3016 - val_loss: 1.5275 - val_acc: 0.3600\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5314 - acc: 0.3584 - val_loss: 1.5226 - val_acc: 0.3600\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 1.5401 - acc: 0.3168 - val_loss: 1.5160 - val_acc: 0.3500\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 24s 490ms/step - loss: 1.5339 - acc: 0.3168 - val_loss: 1.5104 - val_acc: 0.3500\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 25s 490ms/step - loss: 1.5335 - acc: 0.3208 - val_loss: 1.5082 - val_acc: 0.3600\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 24s 490ms/step - loss: 1.5232 - acc: 0.3320 - val_loss: 1.5033 - val_acc: 0.3500\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 1.5192 - acc: 0.3328 - val_loss: 1.4982 - val_acc: 0.3500\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 25s 490ms/step - loss: 1.5162 - acc: 0.3384 - val_loss: 1.4939 - val_acc: 0.3400\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 1.5132 - acc: 0.3088 - val_loss: 1.4891 - val_acc: 0.3600\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 1.5188 - acc: 0.3352 - val_loss: 1.4871 - val_acc: 0.3500\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 24s 490ms/step - loss: 1.5073 - acc: 0.3544 - val_loss: 1.4834 - val_acc: 0.3800\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 1.5236 - acc: 0.3208 - val_loss: 1.4815 - val_acc: 0.3700\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 1.4977 - acc: 0.3416 - val_loss: 1.4780 - val_acc: 0.3600\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.4985 - acc: 0.3624 - val_loss: 1.4761 - val_acc: 0.3600\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 1.5018 - acc: 0.3464 - val_loss: 1.4733 - val_acc: 0.3400\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.4993 - acc: 0.3448 - val_loss: 1.4683 - val_acc: 0.3700\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 1.5018 - acc: 0.3472 - val_loss: 1.4687 - val_acc: 0.3500\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 1.4879 - acc: 0.3496 - val_loss: 1.4628 - val_acc: 0.3500\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 1.4905 - acc: 0.3384 - val_loss: 1.4620 - val_acc: 0.3700\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 1.4741 - acc: 0.3496 - val_loss: 1.4575 - val_acc: 0.3400\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 1.4881 - acc: 0.3312 - val_loss: 1.4570 - val_acc: 0.3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13eb46cbdd8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_Adam.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=50, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          65600     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 221,573\n",
      "Trainable params: 221,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# let's try tye base model w/ decreased learning rate and Adam optimizer (vs. SGD)\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 20s 394ms/step - loss: 1.6114 - acc: 0.1944 - val_loss: 1.6070 - val_acc: 0.2000\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.6071 - acc: 0.2216 - val_loss: 1.6047 - val_acc: 0.2300\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 1.6029 - acc: 0.2496 - val_loss: 1.6041 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.6034 - acc: 0.2416 - val_loss: 1.6025 - val_acc: 0.2700\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 1.6035 - acc: 0.2352 - val_loss: 1.6012 - val_acc: 0.2400\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 1.6022 - acc: 0.2616 - val_loss: 1.6001 - val_acc: 0.3000\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 1.5990 - acc: 0.2720 - val_loss: 1.5991 - val_acc: 0.2800\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 1.5956 - acc: 0.2792 - val_loss: 1.5973 - val_acc: 0.3000\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 1.5946 - acc: 0.2832 - val_loss: 1.5953 - val_acc: 0.2900\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 1.5919 - acc: 0.2808 - val_loss: 1.5931 - val_acc: 0.3100\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 1.5920 - acc: 0.2680 - val_loss: 1.5902 - val_acc: 0.3100\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 1.5831 - acc: 0.3096 - val_loss: 1.5870 - val_acc: 0.3200\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 1.5815 - acc: 0.3168 - val_loss: 1.5843 - val_acc: 0.3600\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 27s 546ms/step - loss: 1.5827 - acc: 0.3016 - val_loss: 1.5806 - val_acc: 0.3000\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 1.5760 - acc: 0.3216 - val_loss: 1.5782 - val_acc: 0.3400\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 59s 1s/step - loss: 1.5708 - acc: 0.3408 - val_loss: 1.5730 - val_acc: 0.3300\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 1.5645 - acc: 0.3184 - val_loss: 1.5686 - val_acc: 0.3500\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 1.5661 - acc: 0.3240 - val_loss: 1.5637 - val_acc: 0.3300\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 27s 541ms/step - loss: 1.5564 - acc: 0.3504 - val_loss: 1.5593 - val_acc: 0.3200\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 29s 589ms/step - loss: 1.5533 - acc: 0.3568 - val_loss: 1.5545 - val_acc: 0.3400\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 1.5467 - acc: 0.3432 - val_loss: 1.5512 - val_acc: 0.3400\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 1.5439 - acc: 0.3472 - val_loss: 1.5449 - val_acc: 0.3300\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 1.5390 - acc: 0.3512 - val_loss: 1.5418 - val_acc: 0.3300\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 1.5334 - acc: 0.3512 - val_loss: 1.5385 - val_acc: 0.3200\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 1.5288 - acc: 0.3408 - val_loss: 1.5321 - val_acc: 0.3700\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 1.5318 - acc: 0.3304 - val_loss: 1.5263 - val_acc: 0.3300\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 1.5155 - acc: 0.3480 - val_loss: 1.5207 - val_acc: 0.3700\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.5055 - acc: 0.3600 - val_loss: 1.5199 - val_acc: 0.3600\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 1.5174 - acc: 0.3464 - val_loss: 1.5136 - val_acc: 0.3300\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 1.5017 - acc: 0.3560 - val_loss: 1.5101 - val_acc: 0.3700\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 1.4957 - acc: 0.3776 - val_loss: 1.5031 - val_acc: 0.3700\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 1.5055 - acc: 0.3504 - val_loss: 1.5009 - val_acc: 0.4100\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.4852 - acc: 0.3648 - val_loss: 1.4951 - val_acc: 0.3800\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 1.4716 - acc: 0.3936 - val_loss: 1.4908 - val_acc: 0.3800\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 1.4791 - acc: 0.3752 - val_loss: 1.4851 - val_acc: 0.3700\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 1.4824 - acc: 0.3680 - val_loss: 1.4810 - val_acc: 0.3600\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 25s 504ms/step - loss: 1.4758 - acc: 0.3640 - val_loss: 1.4797 - val_acc: 0.3700\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 1.4670 - acc: 0.3720 - val_loss: 1.4738 - val_acc: 0.3500\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 1.4676 - acc: 0.3800 - val_loss: 1.4758 - val_acc: 0.4100\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.4638 - acc: 0.3848 - val_loss: 1.4712 - val_acc: 0.4000\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 1.4583 - acc: 0.3808 - val_loss: 1.4717 - val_acc: 0.4000\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 1.4532 - acc: 0.3856 - val_loss: 1.4679 - val_acc: 0.3900\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 1.4479 - acc: 0.3704 - val_loss: 1.4603 - val_acc: 0.3400\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 1.4386 - acc: 0.3968 - val_loss: 1.4635 - val_acc: 0.4000\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 1.4341 - acc: 0.4072 - val_loss: 1.4596 - val_acc: 0.4200\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 1.4464 - acc: 0.3784 - val_loss: 1.4512 - val_acc: 0.3700\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 1.4322 - acc: 0.3968 - val_loss: 1.4515 - val_acc: 0.4200\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 1.4216 - acc: 0.4144 - val_loss: 1.4488 - val_acc: 0.3900\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 1.4243 - acc: 0.4096 - val_loss: 1.4436 - val_acc: 0.3900\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 1.4407 - acc: 0.3768 - val_loss: 1.4403 - val_acc: 0.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13eb40f7470>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=50, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the wider model (with less stride, smaller Convolution filter) w/ more trainable parameters and the simple base model appear to perform the best on validation data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.16%\n"
     ]
    }
   ],
   "source": [
    "# let's test on these iterations of the base, deep and wide models\n",
    "\n",
    "base_scores = base_model.evaluate_generator(test_generator, steps=25)\n",
    "print(\"Accuracy: %.2f%%\" % (base_scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.64%\n"
     ]
    }
   ],
   "source": [
    "deep_model_Adam_scores = deep_model_Adam.evaluate_generator(test_generator, steps=25)\n",
    "print(\"Accuracy: %.2f%%\" % (deep_model_Adam_scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.58%\n"
     ]
    }
   ],
   "source": [
    "wide_model_slow_learn_scores = wide_model_slow_learn.evaluate_generator(test_generator, steps=25)\n",
    "print(\"Accuracy: %.2f%%\" % (wide_model_slow_learn_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps... pick top 2 or 3 models and test and note which performs best.  use top 2-3 on broader image data set (simple_CNN notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models and weights just in case... will need to retrain on broader image sets anyways\n",
    "base_model.save('subset_base_model.h5')\n",
    "deep_model_Adam.save('subset_deep_model_Adam.h5')\n",
    "wide_model_slow_learn.save('subset_wide_model_slow_learn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
