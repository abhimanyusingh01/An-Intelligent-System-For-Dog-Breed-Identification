{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "seed = 16\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11775377860863669033\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1493781708\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 10596170577812394798\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#check using system GPU for processing and declaring system/GPU parameters\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# configure tensorflow before fitting model\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.Session(config=tf_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare ImageDataGenerator and flow_from_directory vars\n",
    "batch_size=10\n",
    "num_classes = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing directory for flow_from_directory method\n",
    "os.chdir('C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain train and test labels\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#y_train_rough = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "\n",
    "#y_test = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\test_list.mat''')['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "files = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['file_list']\n",
    "labels = [item for label in labels for item in label] #this is flattening a list of lists, because for some reason ever label is stored as a list\n",
    "files = [item for file in files for item in file]\n",
    "df = pd.DataFrame({'labels':labels, 'files':files})\n",
    "train, validate = train_test_split(df, test_size = 0.2, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['files']\n",
    "y_train = to_categorical(train['labels'])\n",
    "X_val = validate['files']\n",
    "y_val = to_categorical(validate['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9600 images belonging to 120 classes.\n",
      "Found 2400 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15, shear_range=0.1, channel_shift_range=20,\n",
    "                                    width_shift_range=0.1,  height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True,\n",
    "                                    fill_mode='nearest', rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=10)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('validation', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=10)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('test', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_validation = []\\ny_train = []\\n\\nfor i in range(120):\\n    i = i*100\\n    \\n    #begin_index = train_full_list[i::100]\\n    #end_index = train_full_list[i+100::100]\\n    \\n    slice = y_train_rough[i:i+100,]\\n    y_train.append(slice[:80])\\n    y_validation.append(slice[80:])\\n\\ny_train = np.concatenate(y_train, axis=0)\\ny_validation = np.concatenate(y_validation, axis=0)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain validation labels\n",
    "# no longer used, utilizing sklearn's train_test_split function\n",
    "\n",
    "'''\n",
    "y_validation = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(120):\n",
    "    i = i*100\n",
    "    \n",
    "    #begin_index = train_full_list[i::100]\n",
    "    #end_index = train_full_list[i+100::100]\n",
    "    \n",
    "    slice = y_train_rough[i:i+100,]\n",
    "    y_train.append(slice[:80])\n",
    "    y_validation.append(slice[80:])\n",
    "\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "y_validation = np.concatenate(y_validation, axis=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a simple CNN to start\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import keras.utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          65600     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 251,128\n",
      "Trainable params: 251,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224, 3)\n",
    "\n",
    "# create the model\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(Flatten())\n",
    "\n",
    "base_model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(Dropout(0.2))\n",
    "base_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "300/300 [==============================] - 158s 526ms/step - loss: 4.7910 - acc: 0.0075 - val_loss: 4.7881 - val_acc: 0.0079\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 156s 519ms/step - loss: 4.7896 - acc: 0.0088 - val_loss: 4.7874 - val_acc: 0.0096\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 152s 507ms/step - loss: 4.7915 - acc: 0.0088 - val_loss: 4.7869 - val_acc: 0.0083\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 153s 508ms/step - loss: 4.7880 - acc: 0.0088 - val_loss: 4.7870 - val_acc: 0.0083\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 154s 513ms/step - loss: 4.7886 - acc: 0.0083 - val_loss: 4.7866 - val_acc: 0.0071\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 158s 526ms/step - loss: 4.7872 - acc: 0.0089 - val_loss: 4.7862 - val_acc: 0.0096\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 155s 516ms/step - loss: 4.7890 - acc: 0.0092 - val_loss: 4.7861 - val_acc: 0.0096\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 154s 515ms/step - loss: 4.7859 - acc: 0.0111 - val_loss: 4.7856 - val_acc: 0.0108\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7885 - acc: 0.0105 - val_loss: 4.7854 - val_acc: 0.0121\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7877 - acc: 0.0079 - val_loss: 4.7854 - val_acc: 0.0117\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 160s 534ms/step - loss: 4.7866 - acc: 0.0092 - val_loss: 4.7850 - val_acc: 0.0100\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 162s 539ms/step - loss: 4.7856 - acc: 0.0120 - val_loss: 4.7846 - val_acc: 0.0096\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 159s 530ms/step - loss: 4.7869 - acc: 0.0095 - val_loss: 4.7841 - val_acc: 0.0083\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 158s 525ms/step - loss: 4.7857 - acc: 0.0109 - val_loss: 4.7834 - val_acc: 0.0100\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 156s 522ms/step - loss: 4.7857 - acc: 0.0085 - val_loss: 4.7832 - val_acc: 0.0121\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 157s 522ms/step - loss: 4.7845 - acc: 0.0139 - val_loss: 4.7825 - val_acc: 0.0137\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 160s 534ms/step - loss: 4.7856 - acc: 0.0105 - val_loss: 4.7815 - val_acc: 0.0129\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 159s 531ms/step - loss: 4.7844 - acc: 0.0125 - val_loss: 4.7809 - val_acc: 0.0112\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 158s 528ms/step - loss: 4.7823 - acc: 0.0115 - val_loss: 4.7801 - val_acc: 0.0117\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 157s 525ms/step - loss: 4.7836 - acc: 0.0104 - val_loss: 4.7792 - val_acc: 0.0154\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 156s 521ms/step - loss: 4.7823 - acc: 0.0129 - val_loss: 4.7773 - val_acc: 0.0146\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 159s 529ms/step - loss: 4.7787 - acc: 0.0133 - val_loss: 4.7764 - val_acc: 0.0146\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 180s 601ms/step - loss: 4.7788 - acc: 0.0119 - val_loss: 4.7743 - val_acc: 0.0150\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 221s 738ms/step - loss: 4.7771 - acc: 0.0140 - val_loss: 4.7721 - val_acc: 0.0133\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - 184s 612ms/step - loss: 4.7757 - acc: 0.0124 - val_loss: 4.7696 - val_acc: 0.0142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d10da1c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit the simple CNN using flow from directory \n",
    "\n",
    "base_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 54, 54, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 64)          65600     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 251,640\n",
      "Trainable params: 251,384\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# try base_model with Batch normalization\n",
    "\n",
    "base_model_BN = Sequential()\n",
    "base_model_BN.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN.add(BatchNormalization())\n",
    "base_model_BN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "base_model_BN.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "base_model_BN.add(BatchNormalization())\n",
    "\n",
    "base_model_BN.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN.add(Flatten())\n",
    "\n",
    "base_model_BN.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN.add(Dropout(0.2))\n",
    "base_model_BN.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model_BN.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model_BN.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 241s 804ms/step - loss: 4.9950 - acc: 0.0068 - val_loss: 4.9415 - val_acc: 0.0104\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 166s 552ms/step - loss: 4.9400 - acc: 0.0089 - val_loss: 4.9159 - val_acc: 0.0112\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 157s 522ms/step - loss: 4.9147 - acc: 0.0101 - val_loss: 4.8875 - val_acc: 0.0117\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 158s 527ms/step - loss: 4.8823 - acc: 0.0089 - val_loss: 4.8713 - val_acc: 0.0108\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 165s 551ms/step - loss: 4.8709 - acc: 0.0081 - val_loss: 4.8565 - val_acc: 0.0117\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 161s 536ms/step - loss: 4.8615 - acc: 0.0100 - val_loss: 4.8484 - val_acc: 0.0108\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 156s 520ms/step - loss: 4.8662 - acc: 0.0099 - val_loss: 4.8323 - val_acc: 0.0096\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 156s 519ms/step - loss: 4.8475 - acc: 0.0084 - val_loss: 4.8316 - val_acc: 0.0104\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 154s 514ms/step - loss: 4.8391 - acc: 0.0117 - val_loss: 4.8174 - val_acc: 0.0100\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 156s 520ms/step - loss: 4.8406 - acc: 0.0092 - val_loss: 4.8091 - val_acc: 0.0121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f91eee278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_BN.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_BN.save('base_model_BN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 109, 109, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               1384704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 1,443,512\n",
      "Trainable params: 1,442,808\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# tweak base model... decrease first covnet filter, decease filter size and stride, add Batch Normalization\n",
    "\n",
    "base_model_BN_v2 = Sequential()\n",
    "base_model_BN_v2.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN_v2.add(BatchNormalization())\n",
    "base_model_BN_v2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "base_model_BN_v2.add(Dropout(0.2))\n",
    "\n",
    "base_model_BN_v2.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN_v2.add(BatchNormalization())\n",
    "base_model_BN_v2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "base_model_BN_v2.add(Dropout(0.2))\n",
    "\n",
    "base_model_BN_v2.add(Conv2D(32, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN_v2.add(BatchNormalization())\n",
    "base_model_BN_v2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "base_model_BN_v2.add(Dropout(0.2))\n",
    "base_model_BN_v2.add(Flatten())\n",
    "\n",
    "base_model_BN_v2.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_BN_v2.add(BatchNormalization())\n",
    "base_model_BN_v2.add(Dropout(0.2))\n",
    "\n",
    "base_model_BN_v2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model_BN_v2.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model_BN_v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 166s 552ms/step - loss: 5.5849 - acc: 0.0077 - val_loss: 5.1300 - val_acc: 0.0100\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 161s 535ms/step - loss: 5.5356 - acc: 0.0077 - val_loss: 5.1100 - val_acc: 0.0104\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 162s 539ms/step - loss: 5.4870 - acc: 0.0109 - val_loss: 5.0985 - val_acc: 0.0100\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 169s 562ms/step - loss: 5.4590 - acc: 0.0083 - val_loss: 5.0972 - val_acc: 0.0112\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 166s 554ms/step - loss: 5.4164 - acc: 0.0089 - val_loss: 5.0881 - val_acc: 0.0092\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 177s 588ms/step - loss: 5.3747 - acc: 0.0081 - val_loss: 5.1088 - val_acc: 0.0092\n",
      "Epoch 7/10\n",
      " 70/300 [======>.......................] - ETA: 2:18 - loss: 5.3490 - acc: 0.0097"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fdbae5efef8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m base_model_BN_v2.fit_generator(train_generator, validation_data=validation_generator,\n\u001b[1;32m----> 2\u001b[1;33m                          steps_per_epoch=300, epochs=10, callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model_BN_v2.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying a larger FC layer\n",
    "\n",
    "base_model_v3 = Sequential()\n",
    "base_model_v3.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model_v3.add(Conv2D(32, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model_v3.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(Flatten())\n",
    "\n",
    "base_model_v3.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(Dropout(0.2))\n",
    "base_model_v3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model_v3.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model_v3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 25, 25, 64)        55360     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               73984     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 259,768\n",
      "Trainable params: 259,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# trying deep_model architecture (in this case, adding additional conv layer and pooling after 2 conv +activation layers\n",
    "\n",
    "deep_model = Sequential()\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Conv2D(96, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Flatten())\n",
    "\n",
    "deep_model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Dropout(0.2))\n",
    "deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "# use existing adam optimizer\n",
    "deep_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 4.7901 - acc: 0.0076 - val_loss: 4.7877 - val_acc: 0.0071\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 156s 520ms/step - loss: 4.7890 - acc: 0.0063 - val_loss: 4.7873 - val_acc: 0.0063\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 150s 499ms/step - loss: 4.7874 - acc: 0.0072 - val_loss: 4.7871 - val_acc: 0.0121\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 155s 517ms/step - loss: 4.7895 - acc: 0.0064 - val_loss: 4.7872 - val_acc: 0.0071\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 156s 520ms/step - loss: 4.7877 - acc: 0.0085 - val_loss: 4.7871 - val_acc: 0.0079\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 153s 509ms/step - loss: 4.7875 - acc: 0.0091 - val_loss: 4.7870 - val_acc: 0.0088\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 156s 519ms/step - loss: 4.7879 - acc: 0.0087 - val_loss: 4.7868 - val_acc: 0.0092\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7885 - acc: 0.0067 - val_loss: 4.7870 - val_acc: 0.0092\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 154s 513ms/step - loss: 4.7874 - acc: 0.0077 - val_loss: 4.7868 - val_acc: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a8e593860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=50, callbacks=[early_stopping])\n",
    "\n",
    "# not enough steps per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 410s 512ms/step - loss: 4.7871 - acc: 0.0096 - val_loss: 4.7863 - val_acc: 0.0100\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 422s 527ms/step - loss: 4.7871 - acc: 0.0090 - val_loss: 4.7855 - val_acc: 0.0125\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 419s 524ms/step - loss: 4.7865 - acc: 0.0082 - val_loss: 4.7846 - val_acc: 0.0108\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 407s 509ms/step - loss: 4.7850 - acc: 0.0117 - val_loss: 4.7827 - val_acc: 0.0087\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 405s 506ms/step - loss: 4.7836 - acc: 0.0097 - val_loss: 4.7805 - val_acc: 0.0112\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 403s 504ms/step - loss: 4.7829 - acc: 0.0099 - val_loss: 4.7776 - val_acc: 0.0100\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 412s 515ms/step - loss: 4.7767 - acc: 0.0127 - val_loss: 4.7714 - val_acc: 0.0104\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 416s 519ms/step - loss: 4.7750 - acc: 0.0108 - val_loss: 4.7661 - val_acc: 0.0142\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 429s 536ms/step - loss: 4.7640 - acc: 0.0129 - val_loss: 4.7595 - val_acc: 0.0133\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 435s 543ms/step - loss: 4.7642 - acc: 0.0128 - val_loss: 4.7487 - val_acc: 0.0104\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 422s 528ms/step - loss: 4.7544 - acc: 0.0126 - val_loss: 4.7403 - val_acc: 0.0133\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 394s 492ms/step - loss: 4.7433 - acc: 0.0165 - val_loss: 4.7279 - val_acc: 0.0150\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 406s 507ms/step - loss: 4.7379 - acc: 0.0157 - val_loss: 4.7165 - val_acc: 0.0129\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 406s 508ms/step - loss: 4.7217 - acc: 0.0167 - val_loss: 4.7020 - val_acc: 0.0146\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 415s 518ms/step - loss: 4.7149 - acc: 0.0164 - val_loss: 4.6868 - val_acc: 0.0150\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 424s 530ms/step - loss: 4.7067 - acc: 0.0164 - val_loss: 4.6804 - val_acc: 0.0167\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 414s 517ms/step - loss: 4.6944 - acc: 0.0185 - val_loss: 4.6674 - val_acc: 0.0200\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 424s 530ms/step - loss: 4.6804 - acc: 0.0198 - val_loss: 4.6484 - val_acc: 0.0179\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 420s 525ms/step - loss: 4.6752 - acc: 0.0194 - val_loss: 4.6574 - val_acc: 0.0192\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 416s 520ms/step - loss: 4.6697 - acc: 0.0199 - val_loss: 4.6397 - val_acc: 0.0221\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 410s 512ms/step - loss: 4.6486 - acc: 0.0211 - val_loss: 4.6208 - val_acc: 0.0221\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 405s 507ms/step - loss: 4.6522 - acc: 0.0210 - val_loss: 4.6114 - val_acc: 0.0212\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 412s 515ms/step - loss: 4.6451 - acc: 0.0214 - val_loss: 4.6029 - val_acc: 0.0212\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 417s 521ms/step - loss: 4.6414 - acc: 0.0216 - val_loss: 4.5922 - val_acc: 0.0217\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 415s 519ms/step - loss: 4.6260 - acc: 0.0225 - val_loss: 4.5795 - val_acc: 0.0221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a93d4b5f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=800, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.save('deep_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_66 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 54, 54, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 25, 25, 64)        55360     \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 23, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1028)              297092    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 120)               123480    \n",
      "=================================================================\n",
      "Total params: 576,284\n",
      "Trainable params: 575,900\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# trying deep model with batch normalization and bigger FC layer\n",
    "deep_model_BN = Sequential()\n",
    "deep_model_BN.add(Conv2D(96, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_BN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "deep_model_BN.add(BatchNormalization())\n",
    "\n",
    "deep_model_BN.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_BN.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_BN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "deep_model_BN.add(BatchNormalization())\n",
    "\n",
    "deep_model_BN.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_BN.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model_BN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "deep_model_BN.add(BatchNormalization())\n",
    "deep_model_BN.add(Flatten())\n",
    "\n",
    "deep_model_BN.add(Dense(1028, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model_BN.add(Dropout(0.2))\n",
    "deep_model_BN.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "# use existing adam optimizer\n",
    "deep_model_BN.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(deep_model_BN.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 424s 530ms/step - loss: 5.1990 - acc: 0.0086 - val_loss: 4.9286 - val_acc: 0.0133\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 419s 524ms/step - loss: 4.9617 - acc: 0.0112 - val_loss: 4.8573 - val_acc: 0.0137\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 410s 513ms/step - loss: 4.8990 - acc: 0.0109 - val_loss: 4.8128 - val_acc: 0.0150\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 424s 529ms/step - loss: 4.8545 - acc: 0.0117 - val_loss: 4.7910 - val_acc: 0.0142\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 437s 547ms/step - loss: 4.8269 - acc: 0.0142 - val_loss: 4.7690 - val_acc: 0.0137\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 400s 500ms/step - loss: 4.8040 - acc: 0.0145 - val_loss: 4.7478 - val_acc: 0.0200\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 412s 515ms/step - loss: 4.7774 - acc: 0.0149 - val_loss: 4.7314 - val_acc: 0.0137\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 407s 509ms/step - loss: 4.7546 - acc: 0.0177 - val_loss: 4.7217 - val_acc: 0.0187\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 418s 523ms/step - loss: 4.7404 - acc: 0.0164 - val_loss: 4.7051 - val_acc: 0.0221\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 414s 517ms/step - loss: 4.7310 - acc: 0.0174 - val_loss: 4.6947 - val_acc: 0.0192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f958fa1d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_BN.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=800, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_BN.save('deep_model_BN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_79 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 52, 52, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 52, 52, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 26, 26, 1024)      33792     \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 26, 26, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_16  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 176,452\n",
      "Trainable params: 176,318\n",
      "Non-trainable params: 134\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# old iteration, retry with Batch Normalization and Global Average Pooling\n",
    "# note to self, may try using this on pretrained VGG16 model to reduce size of FC layer\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(BatchNormalization(input_shape=input_shape))\n",
    "model_3.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_3.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_3.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model_3.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(GlobalAveragePooling2D())\n",
    "\n",
    "model_3.add(Dense(num_classes, activation='softmax'))\n",
    "     \n",
    "\n",
    "# Compile model\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 77s 255ms/step - loss: 4.8914 - acc: 0.0063 - val_loss: 4.8358 - val_acc: 0.0100\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 74s 246ms/step - loss: 4.8963 - acc: 0.0047 - val_loss: 4.8213 - val_acc: 0.0113\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 76s 254ms/step - loss: 4.8703 - acc: 0.0083 - val_loss: 4.8141 - val_acc: 0.0088\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 77s 257ms/step - loss: 4.8410 - acc: 0.0040 - val_loss: 4.8100 - val_acc: 0.0088\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 74s 246ms/step - loss: 4.8457 - acc: 0.0067 - val_loss: 4.8071 - val_acc: 0.0083\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 75s 250ms/step - loss: 4.8144 - acc: 0.0133 - val_loss: 4.8057 - val_acc: 0.0096\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 78s 259ms/step - loss: 4.8048 - acc: 0.0073 - val_loss: 4.8039 - val_acc: 0.0075\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 76s 253ms/step - loss: 4.8328 - acc: 0.0073 - val_loss: 4.8026 - val_acc: 0.0088\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 76s 252ms/step - loss: 4.8302 - acc: 0.0083 - val_loss: 4.7999 - val_acc: 0.0096\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 75s 250ms/step - loss: 4.8163 - acc: 0.0083 - val_loss: 4.7988 - val_acc: 0.0096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28fd8cfeb38>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                    steps_per_epoch=300, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_88 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 5, 5, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_19  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 779,812\n",
      "Trainable params: 779,294\n",
      "Non-trainable params: 518\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# DONT USE\n",
    "\n",
    "incr_layer_model = Sequential()\n",
    "incr_layer_model.add(BatchNormalization(input_shape=input_shape))\n",
    "incr_layer_model.add(Conv2D(16, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "incr_layer_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "incr_layer_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "incr_layer_model.add(Dropout(0.2))\n",
    "incr_layer_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "incr_layer_model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "incr_layer_model.add(Dropout(0.2))\n",
    "incr_layer_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "incr_layer_model.add(Conv2D(128, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "incr_layer_model.add(Dropout(0.2))\n",
    "incr_layer_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "incr_layer_model.add(Conv2D(256, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "incr_layer_model.add(BatchNormalization())\n",
    "incr_layer_model.add(Dropout(0.2))\n",
    "incr_layer_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "incr_layer_model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "incr_layer_model.add(Dropout(0.2))\n",
    "incr_layer_model.add(GlobalAveragePooling2D())\n",
    "\n",
    "incr_layer_model.add(Dense(num_classes, activation='softmax'))\n",
    "     \n",
    "\n",
    "# Compile model\n",
    "incr_layer_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(incr_layer_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_131 (Bat (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_256 (Conv2D)          (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_226 (MaxPoolin (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_257 (Conv2D)          (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_227 (MaxPoolin (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_258 (Conv2D)          (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_228 (MaxPoolin (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_229 (MaxPoolin (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_260 (Conv2D)          (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_230 (MaxPoolin (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_261 (Conv2D)          (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_231 (MaxPoolin (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1, 1, 2048)        67584     \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_35  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 426,084\n",
      "Trainable params: 426,078\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wide_model_slow_learn = Sequential()\n",
    "\n",
    "wide_model_slow_learn.add(BatchNormalization(input_shape=input_shape,))\n",
    "wide_model_slow_learn.add(Conv2D(64, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Dense(2048, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(Dropout(0.2))\n",
    "wide_model_slow_learn.add(GlobalAveragePooling2D())\n",
    "\n",
    "wide_model_slow_learn.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "wide_model_slow_learn.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(wide_model_slow_learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 195s 244ms/step - loss: 4.7125 - acc: 0.0151 - val_loss: 4.7043 - val_acc: 0.0171\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 218s 273ms/step - loss: 4.6934 - acc: 0.0158 - val_loss: 4.6914 - val_acc: 0.0204\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 255s 318ms/step - loss: 4.6904 - acc: 0.0165 - val_loss: 4.6830 - val_acc: 0.0192\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 202s 253ms/step - loss: 4.6855 - acc: 0.0161 - val_loss: 4.6787 - val_acc: 0.0171\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 193s 241ms/step - loss: 4.6642 - acc: 0.0163 - val_loss: 4.6624 - val_acc: 0.0225\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 192s 240ms/step - loss: 4.6658 - acc: 0.0166 - val_loss: 4.6538 - val_acc: 0.0208\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 191s 239ms/step - loss: 4.6542 - acc: 0.0169 - val_loss: 4.6458 - val_acc: 0.0229\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 195s 244ms/step - loss: 4.6412 - acc: 0.0165 - val_loss: 4.6381 - val_acc: 0.0238\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 195s 244ms/step - loss: 4.6446 - acc: 0.0161 - val_loss: 4.6314 - val_acc: 0.0225\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 195s 243ms/step - loss: 4.6334 - acc: 0.0183 - val_loss: 4.6232 - val_acc: 0.0208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ff891b978>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_model_slow_learn.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=800, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_model_slow_learn.save('wide_model_slow_learn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_202 (Conv2D)          (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_176 (MaxPoolin (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 111, 111, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_177 (MaxPoolin (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 54, 54, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_178 (MaxPoolin (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 12, 12, 1024)      33792     \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 12, 12, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_28  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 251,544\n",
      "Trainable params: 251,224\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wide_model_fast_learn = Sequential()\n",
    "wide_model_fast_learn.add(Conv2D(64, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model_fast_learn.add(BatchNormalization())\n",
    "\n",
    "wide_model_fast_learn.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model_fast_learn.add(BatchNormalization())\n",
    "\n",
    "wide_model_fast_learn.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_fast_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model_fast_learn.add(BatchNormalization())\n",
    "\n",
    "wide_model_fast_learn.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(Dropout(0.2))\n",
    "\n",
    "wide_model_fast_learn.add(GlobalAveragePooling2D())\n",
    "wide_model_fast_learn.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "\n",
    "adam_op = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "wide_model_fast_learn.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(wide_model_fast_learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 215s 268ms/step - loss: 5.0008 - acc: 0.0029 - val_loss: 4.9147 - val_acc: 0.0083\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 208s 259ms/step - loss: 4.8804 - acc: 0.0038 - val_loss: 5.1029 - val_acc: 0.0063\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 200s 250ms/step - loss: 4.8519 - acc: 0.0000e+00 - val_loss: 4.7985 - val_acc: 0.0083\n",
      "Epoch 4/10\n",
      " 27/800 [>.............................] - ETA: 1:54 - loss: 4.8807 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-95d335f3ebed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m wide_model_fast_learn.fit_generator(train_generator, validation_data=validation_generator,\n\u001b[1;32m----> 2\u001b[1;33m                          steps_per_epoch=800, epochs=10, callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wide_model_fast_learn.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=800, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
